**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 – Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group \#:      |  1   |
| -------------- | --- |
| Student Names: |   Harris Hasnain   |
|                |   Houssem Zaggar  |
|                |   Spencer van Roessel  |
|                |   Kaylyn Tanton |

(Note that some labs require individual reports while others require one report
for each group. Please see each lab document for details.)

# 1 Introduction

This lab served as an introduction to white-box testing design and implementation. We utilized coverage metrics to analyze the effectiveness of our test suite from the previous assignment, then designed new white-box test cases using control-flow coverage metrics such as statement and branch coverage and measued the improvement relative to our original code, and measured the data-flow coverage of specific methods. This lab provided experience developing and analyzing white-box tests and demonstrated the benefits and drawbacks of coverage-based testing relative to requirement-based testing.

# 2 Manual data-flow coverage calculations for X and Y methods

Text…

# 3 A detailed description of the testing strategy for the new unit test

Note: Method coverage was used instead of condition coverage, because none of the coverage tools provided to us appeared to have condition coverage as a metric according to their documentation

The strategy to develop new test cases for the suite to improve the coverage metrics will be implemented as follows: focus on method coverage first for all methods, to ensure all methods are in the test suite. This can be implemented by making sure each method has at least one associated test in the suite. Then write tests to maximize statement coverage to cover all of the lines in each method. The coverage tool should highlight uncovered lines in the DataUtilities class, so new tests should be added to reach lines that have not been covered by the existing tests. Finally, the tests for branch coverage should be implemented for paths that are not reached by the tests developed so far. This can be done by viewing the DataUtilities class and checking all of the decision paths, then comparing them using the tool to the current test suite to check which path outcomes are covered, and write tests for the paths that are not covered. This should maximize all 3 coverage metrics if new tests are implemented in this manner.


# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

Note: all test methods that increased coverage can be found in the JFreeChart_Lab3/src/org/jfree/data/test/DataUtilitiesTest.java file in the repository

1. calculateColumnTotalWithNullValues
This function increased branch coverage by testing the path in the calculateColumnTotal function that executes only when one of the input values is null

2. calculateRowTotalWithNullInput
This function increased branch coverage by testing the path in the calculateRowTotal function that executes only when one of the input values is null

3. testEqualAIsNull
This function increased branch coverage by testing the path in the equal function that executes only when the first input array is null

4. testEqualBIsNull
This function increased branch coverage by testing the path in the equal function that executes only when the second input array is null

5. testCloneNullRow
This function increased branch coverage by testing the path in the clone function that executes only when one of the input array rows is null


# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

Note: The actual coverage output screenshots from eclipse are in the “DataUtilities Coverage Screenshots” folder in the repository, these are the results in tabular form.

![Coverage Table](DataUtilities%20Coverage%20Screenshots/coverage_table.jpg)

IMPORTANT Coverage Notes:
1. Method coverage was used instead of condition coverage, because none of the coverage tools provided to us appeared to have condition coverage as a metric according to their documentation
2. Statement coverage for the DataUtilities class was 88.4% instead of 90% as required in the handout. This is because multiple methods in the class had infeasible paths (some screenshots of these infeasible paths are in the “DataUtilities Coverage Screenshots” folder) and therefore, the code within these paths could not be executed. Statement coverage was maximized in every feasible path though, leading to a total statement coverage just shy of 90%, and the branch coverage was above 70% as requested.

# 6 Pros and Cons of coverage tools used and Metrics you report

Text…

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

Text…

# 8 A discussion on how the team work/effort was divided and managed

Text…

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

Text…

# 10 Comments/feedback on the lab itself

Text…
